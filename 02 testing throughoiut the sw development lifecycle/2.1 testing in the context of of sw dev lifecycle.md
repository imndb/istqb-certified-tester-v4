# 2.1 Testing in the Context of a Software Development Lifecycle

A software development lifecycle (SDLC) model def.:
* **an abstract, high-level representation of the software development process**.
* it defines **how different development phases and types of activities** performed within this process **relate to each other**, both logically and chronologically
* eg-s of SDLC models:
  + **sequential development models**
    - eg. waterfall model, V-model
  + **iterative development models**
    - eg. spiral model, prototyping
  + **incremental development models**
    - eg. Unified Process

**Some activities** within software development processes **can also be described by more detailed software development methods and Agile practices**. eg-s:
* acceptance test-driven development (ATDD)
* behavior-driven development (BDD)
* domain-driven design (DDD)
* extreme programming (XP)
* feature-driven development (FDD)
* Kanban
* Lean IT
* Scrum
* test-driven development (TDD)

## 2.1.1. Impact of the Software Development Lifecycle on Testing

**Testing must be adapted to the SDLC** to succeed. **The choice of the SDLC impacts on the:**
* Scope and timing of test activities (e.g., *test levels* and *test types*)
* Level of detail of test documentation
* Choice of *test techniques* and *test approach*
* Extent of *test automation*
* Role and responsibilities of a tester

**In sequential development models**
* in the initial phases testers typically participate in requirement reviews, test analysis, and test design
* The executable code is usually created in the later phases, so typically dynamic testing cannot be performed early in the SDLC.

**In some iterative and incremental development models**
* it is assumed that each iteration delivers a working prototype or product increment
* This implies that in each iteration both *static* and *dynamic testing* may be performed at all *test levels*
* Frequent delivery of increments requires fast feedback and extensive *regression testing*

**Agile software development** assumes that change may occur throughout the project
* Therefore, lightweight work product documentation and extensive *test automation* to make *regression testing* easier are favored
* Also, most of the manual testing tends to be done using experience-based test techniques (see Section 4.4) that do not require extensive prior *test analysis* and *test design*

## 2.1.2. Software Development Lifecycle and Good Testing Practices

**Good testing practices, independent of the chosen SDLC model**, include:
* For every software development activity, there is a corresponding test activity, so that all development activities are subject to *quality control*
* Different *test levels* (see chapter 2.2.1) have specific and different *test objectives*, which allows for testing to be appropriately comprehensive while avoiding redundancy
* *Test analysis* and *test design* for a given *test level* begins during the corresponding development phase of the SDLC, so that testing can adhere to the principle of early testing (see section 1.3)
* Testers are involved in reviewing work products as soon as drafts of this documentation are available, so that this earlier testing and defect detection can support the *shift-left strategy* (see section 2.1.5)

## 2.1.3. Testing as a Driver for Software Development

**TDD**, **ATDD** and **BDD** are similar development approaches, **where tests are defined as a means of directing development**
* Each of these approaches implements the principle of early testing (see section 1.3) and follows a *shift-left* approach (see section 2.1.5), since the tests are defined before the code is written
* They support an iterative development model

**Test-Driven Development (TDD):**
* Directs the coding through *test cases* (instead of extensive software design) (Beck 2003)
* Tests are written first,
  + then the code is written to satisfy the tests, and
  + then the tests and code are refactored

**Acceptance Test-Driven Development (ATDD)** (see section 4.5.3):
* Derives tests from acceptance criteria as part of the system design process (Gärtner 2011)
* Tests are written before the part of the application is developed to satisfy the tests

**Behavior-Driven Development (BDD):**
* Expresses the desired behavior of an application with *test cases* written in a simple form of natural language, which is easy to understand by stakeholders – usually using the Given/When/Then format. (Chelimsky 2010)
* *Test cases* are then automatically translated into executable tests

For all the above approaches, tests may persist as automated tests to ensure the code quality in future
adaptions / refactoring.

## 2.1.4. DevOps and Testing

DevOps def.:
* is an **organizational approach** aiming **to create synergy** by getting **development** (including testing) and **operations** to work together to achieve a set of common goals
* it **requires a cultural shift** within an organization to bridge the gaps between development (including testing) and operations while treating their functions with equal value
* it **promotes**:
  + team autonomy,
  + fast feedback,
  + integrated toolchains, and technical practices like continuous integration (CI) and continuous delivery (CD)
* This enables the teams to build, test and release high-quality code faster through a DevOps delivery pipeline (Kim 2016).

**benefits of DevOps, from the testing perspective**, include:
* Fast feedback on the code quality, and whether changes adversely affect existing code
* CI promotes a *shift-left approach* in testing (see section 2.1.5) by encouraging developers to submit high quality code accompanied by component tests and *static analysis*
* Promotes automated processes like CI/CD that facilitate establishing stable test environments
* Increases the view on non-functional quality characteristics
  + e.g., performance, reliability
* *Automation* through a delivery pipeline reduces the need for repetitive manual testing
* The risk in regression is minimized due to the scale and range of automated *regression tests*
* DevOps is not without its risks and challenges, which include:
  + The DevOps delivery pipeline must be defined and established
  + CI / CD tools must be introduced and maintained
  + *Test automation* requires additional resources and may be difficult to establish and maintain

Although DevOps comes with a high level of automated testing, manual testing – especially from the
user's perspective – will still be needed.

## 2.1.5. Shift-Left Approach

The **principle of early testing** (see section 1.3) is sometimes referred to as *shift-left* because it is an approach where testing is performed earlier in the SDLC.
* it normally suggests that testing should be done earlier (e.g., not waiting for code to be implemented or for components to be integrated),
* but it does not mean that testing later in the SDLC should be neglected

There are some **good practices** that illustrate how to achieve a “shift-left” in testing, which include:
* **Reviewing the specification from the perspective of testing**.
  + These review activities on specifications often find potential defects, such as ambiguities, incompleteness, and inconsistencies
* **Writing test cases before the code** is written and **have the code run in a test harness** during code implementation
* **Using CI and even better CD** as it comes with fast feedback and automated component tests to accompany source code when it is submitted to the code repository
* Completing **static analysis of source code prior to dynamic testing**, or as part of an automated process
* Performing **non-functional testing starting at the component *test level***, where possible
  + This is a form of *shift-left* as these non-functional test types tend to be performed later in the SDLC when a complete system and a representative test environment are available

A shift-left approach might result in extra training, effort and/or costs earlier in the process but is expected to save efforts and/or costs later in the process.

For the *shift-left* approach it is important that stakeholders are convinced and bought into this concept.

## 2.1.6. Retrospectives and Process Improvement

Retrospectives
* aka “post-project meetings” and project retrospectives
* often held at the end of a project or an iteration, at a release milestone, or can be held when needed
* timing and organization of the retrospectives depend on the particular SDLC model being followed
* ** participants** (not only testers, but also e.g., developers, architects, product owner, business analysts) **discuss**:
  + What was successful, and should be retained?
  + What was not successful and could be improved?
  + How to incorporate the improvements and retain the successes in the future?
* ***results* should be recorded** and are normally **part of the *test completion* report** (see section 5.3.2)
* Retrospectives are critical for the successful implementation of continuous improvement and it is important that any recommended improvements are followed up

**Typical benefits for testing** include:
* Increased test effectiveness / efficiency (e.g., by implementing suggestions for process improvement)
* Increased quality of testware (e.g., by jointly reviewing the test processes)
* Team bonding and learning (e.g., as a result of the opportunity to raise issues and propose
improvement points)
* Improved quality of the test basis (e.g., as deficiencies in the extent and quality of the requirements could be addressed and solved)
* Better cooperation between development and testing (e.g., as collaboration is reviewed and optimized regularly)

