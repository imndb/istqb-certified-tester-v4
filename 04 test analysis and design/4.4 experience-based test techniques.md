# 4.4. Experience-based Test Techniques

commonly used experience-based *test techniques* discussed here:
* *error guessing*
* *exploratory testing*
* *checklist-based testing*

## 4.4.1. Error Guessing

***error guessing***:
* a technique **used to anticipate** the occurrence of errors, defects, and failures, **based on the testerâ€™s knowledge**
* **including**:
  + how the application has worked in the past
  + the types of errors the developers tend to make & the types of defects that result from these errors
  + the types of failures that have occurred in other, similar applications

**in general**, errors, defects and **failures may be related to**
* **input**
  + eg. correct input not accepted, parameters wrong or missing
* **output**
  + eg. wrong format, wrong result
* **logic**
  + eg. missing cases, wrong operator
* **computation**
  + eg. incorrect operand, wrong computation
* **interfaces**
  + eg. parameter mismatch, incompatible types
* **data**
  + eg. incorrect initialization, wrong type

**fault attacks**
* **a methodical approach to** the implementation of *error guessing*
* it **requires the tester**
  + to create or acquire **a list of possible** errors, **defects** and failures and
  + to **design tests that will identify defects associated** with the errors, expose the defects, or cause the failures
* these **lists can be built based on**
  + experience,
  + defect and failure data, or
  + from common knowledge about why software fails

see (Whittaker 2002, Whittaker 2003, Andrews 2006) for more information on *error guessing* and fault attacks

## 4.4.2. Exploratory Testing

**in *exploratory testing***,
* **tests are simultaneously designed, executed, and evaluated while the tester learns** about the test object
* testing is used to
  + **learn more about** the test object,
  + **explore it more deeply** with focused tests,
  + **create tests for untested** areas

**session-based approach**
* ***exploratory testing* is sometimes conducted using session-based testing** to structure the testing
* **in a session-based approach**, *exploratory testing* is conducted within **a defined time-box**
  + the tester uses **a test charter** containing test objectives to guide the testing
  + the **test session is usually followed by a debriefing**
    - that involves a discussion **between the tester and stakeholders** interested in the test results of the test session
  + in this approach **test objectives may be treated as high-level test conditions**
  + coverage items are identified and exercised during the test session
  + the tester may use **test session sheets to document the steps** followed and **the discoveries** made

***exploratory testing* is useful when**
* there are **few or inadequate specifications**,
* there is **significant time pressure** on the testing
* **to complement other more formal** *test techniques*

***exploratory testing* is more effective** when
* the tester is **experienced**,
* has **domain knowledge**
* has **a high degree of essential skills**,
  + like analytical skills, curiosity and creativeness (see section 1.5.1)

***exploratory testing* can incorporate** the use of **other *test techniques***
* eg. equivalence partitioning

more info in (Kaner 1999, Whittaker 2009, Hendrickson 2013)

## 4.4.3. Checklist-Based Testing

**in *checklist-based testing***
* a tester designs, implements, and executes tests to cover test conditions **from a checklist**
* **checklists can be built based on**
  + experience,
  + knowledge about what is important for the user, or
  + an understanding of why and how software fails
* **checklists should not contain**
  + items that can be checked automatically,
  + items better suited as entry/exit criteria, or
  + items that are too general (Brykczynski 1999)

**checklist items** are often phrased **in the form of a question**
* it **should be possible to check each item separately and directly**
* these **items may refer to**
  + requirements,
  + graphical interface properties,
  + quality characteristics or
  + other forms of test conditions
* checklists **can be created to support various test types**, including
  + functional and non-functional testing
    - eg. 10 heuristics for usability testing (Nielsen 1994)

some **checklist entries**
* **may gradually become less effective** over time
  + because the developers will learn to avoid making the same errors
* **new entries may also need to be added**
  + to reflect newly found high severity defects
* **therefore**, checklists **should be regularly updated** based on defect analysis
* **however**, care should be taken to **avoid letting the checklist become too long** (Gawande 2009)

**use**:
* **in the absence of detailed test cases**,
  + ***checklist-based testing* can provide**
    - guidelines,
    - some degree of consistency for the testing
* **if checklists are high-level**,
  + some variability in the actual testing is likely to occur,
  + resulting in potentially greater coverage but less repeatability
