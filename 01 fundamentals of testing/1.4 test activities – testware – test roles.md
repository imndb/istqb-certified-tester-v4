# 1.4. Test Activities, Testware and Test Roles

Testing is context dependent, but, at a high level, there are common sets of test activities
* without which testing is less likely to achieve test objectives.
* These sets of test activities form a test process.
  + The test process can be tailored to a given situation based on various factors.
    - Which test activities are included in this test process, how they are implemented, and when they occur is normally decided as part of the test planning for the specific situation (see section 5.1).

The following sections describe the general aspects of this test process in terms of:
* test activities and tasks,
* the impact of context,
* testware,
* traceability between the test basis and testware, and
* testing roles.

The ISO/IEC/IEEE 29119-2 standard provides further information about test processes.

## 1.4.1. Test Activities and Tasks

A test process usually consists of the main groups of activities described below.
* Although many of these activities may appear to follow a logical sequence, they are often implemented iteratively or in parallel.
* They usually need to be tailored to the system and the project.

**Test planning** consists of:
* defining the *test objectives* and
* then selecting an approach that best achieves the objectives within the constraints imposed by the overall context. * Test planning is further explained in section 5.1.

**Test monitoring and control**
* *Test monitoring* involves the ongoing checking of all test activities and the comparison of actual progress against the plan.
* *Test control* involves taking the actions necessary to meet the objectives of testing.
* both are further explained in section 5.3

**Test analysis**
* includes analyzing the *test basis*
  + to identify testable features and
  + to define and prioritize associated *test conditions*, together with the related *risks* and *risk levels* (see section 5.2).
* The *test basis* and the *test objects* are also evaluated
  + to identify *defects* they may contain and to assess their testability.
* often supported by the use of *test techniques* (see chapter 4).
* answers the question “what to test?” in terms of measurable coverage criteria.

**Test design**
* includes elaborating the *test conditions* into *test cases* and other *testware* (e.g., test charters).
* This often involves the identification of *coverage items*, which serve as a guide to specify test case inputs.
* *Test techniques* (see chapter 4) can be used to support this activity.
* also includes:
  + defining the *test data* requirements,
  + designing the test environment and identifying any other required infrastructure and tools.
* Test design answers the question “how to test?”.

**Test implementation**
* includes creating or acquiring the *testware* necessary for test execution (eg. *test data*).
* Test cases can be organized into *test procedures* and are often assembled into test suites.
* Manual and automated test scripts are created.
* *Test procedures* are prioritized and arranged within a *test execution* schedule for efficient *test execution* (see section 5.1.5).
* The test environment is built and verified to be set up correctly.

**Test execution**
* includes running the tests in accordance with the *test execution* schedule (test runs).
* may be manual or automated.
* can take many forms, including continuous testing or pair testing sessions.
* Actual test results are compared with the expected results.
* The test results are logged.
* Anomalies are analyzed to identify their likely causes.
  + This analysis allows us to report the anomalies based on the *failures* observed (see section 5.5).

**Test completion** activities
* usually occur at project milestones (e.g., release, end of iteration, test level completion) for any unresolved defects, change requests or product backlog items created.
* Any testware that may be useful in the future is identified and archived or handed over to the appropriate teams.
* The test environment is shut down to an agreed state.
* The test activities are analyzed to identify lessons learned and improvements for future iterations, releases, or projects (see section 2.1.6).
* A *test completion report* is created and communicated to the stakeholders.
